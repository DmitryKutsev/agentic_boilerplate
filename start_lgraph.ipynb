{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import together\n",
    "import chromadb\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from langsmith import traceable\n",
    "\n",
    "from tavily import TavilyClient\n",
    "from typing_extensions import TypedDict\n",
    "from openai import OpenAI\n",
    "from together import Together\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "from langgraph.graph import END, StateGraph, START, MessagesState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from dotenv.main import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGCHAIN_TRACING_V2 = True\n",
    "LANGCHAIN_ENDPOINT = \"https://api.smith.langchain.com\"\n",
    "LANGCHAIN_PROJECT = \"my_test_project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOGETHER_API_KEY = os.getenv(\"TOGETHER_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "CURR_LLM_MODEL = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<together.client.Together at 0x1759fc530>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together_client = wrap_openai(Together(api_key=TOGETHER_API_KEY))\n",
    "together_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def llm_pipeline(user_input: str) -> str:\n",
    "    result = together_client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": user_input}], model=CURR_LLM_MODEL\n",
    "    )\n",
    "    return result.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'m an AI model known as Llama. Llama stands for \"Large Language Model Meta AI.\"'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_pipeline(\"Hi there. What model are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHROMA DB SET UP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = OpenAIEmbeddingFunction(\n",
    "    api_key=OPENAI_API_KEY, model_name=EMBEDDING_MODEL\n",
    ")\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(\n",
    "    name=\"marcus_collection\", embedding_function=embedding_function\n",
    ")\n",
    "\n",
    "# collection = chroma_client.get_collection(\n",
    "#     name=\"marcus_collection\", embedding_function=embedding_function\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"marcus_quotes.txt\", \"r\") as reader:\n",
    "    marcus_list = reader.readlines()[:150]\n",
    "ids_list = [f\"id{i+1}\" for i in range(len(marcus_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(documents=marcus_list, ids=ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id1', 'id15']],\n",
       " 'distances': [[0.6908390522003174, 1.1410863399505615]],\n",
       " 'metadatas': [[None, None]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['From my grandfather Verus I learned good morals and the government of my temper.\\n',\n",
       "   'From Maximus I learned self-government, and not to be led aside by anything; and cheerfulness in all circumstances, as well as in illness; and a just admixture in the moral character of sweetness and dignity, and to do what was set before me without complaining. I observed that everybody believed that he thought as he spoke, and that in all that he did he never had any bad intention; and he never showed amazement and surprise, and was never in a hurry, and never put off doing a thing, nor was perplexed nor dejected, nor did he ever laugh to disguise his vexation, nor, on the other hand, was he ever passionate or suspicious. He was accustomed to do acts of beneficence, and was ready to forgive, and was free from all falsehood; and he presented the appearance of a man who could not be diverted from right rather than of a man who had been improved. I observed, too, that no man could ever think that he was despised by Maximus, or ever venture to think himself a better man. He had also the art of being humorous in an agreeable way.\\n']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents', 'distances']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"I want to learn good morals and the government of my temper\"],\n",
    "    n_results=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['From my mother, piety and beneficence, and abstinence, not only from evil deeds, but even from evil thoughts; and further, simplicity in my way of living, far removed from the habits of the rich.\\n']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(\n",
    "    query_texts=[\n",
    "        \"Я хочу научиться хорошим моральным принципам и управлению моим темпераментом\"\n",
    "    ],\n",
    "    n_results=1,\n",
    ")[\"documents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id3']],\n",
       " 'distances': [[1.3667497634887695]],\n",
       " 'metadatas': [[None]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['From my mother, piety and beneficence, and abstinence, not only from evil deeds, but even from evil thoughts; and further, simplicity in my way of living, far removed from the habits of the rich.\\n']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents', 'distances']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(\n",
    "    query_texts=[\n",
    "        \"Я хочу научиться хорошим моральным принципам и управлению моим темпераментом\"\n",
    "    ],\n",
    "    n_results=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TavilyClient setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Who is Aomine Daiki?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'title': 'Daiki Aomine - Kuroko no Basuke Wiki',\n",
       "   'url': 'https://kurokonobasuke.fandom.com/wiki/Daiki_Aomine',\n",
       "   'content': \"Daiki Aomine (青峰 大輝 Aomine Daiki) was the ace player of the renowned Generation of Miracles and was the former partner/light of Tetsuya Kuroko in Teikō Junior High. After hearing a benched teammate insult Tetsuya Kuroko and his style of play during a match against Seirin High, Aomine did not hesitate to slam him against the lockers and warn that he, as someone who couldn't even earn a spot on the court, had no right to comment on the players' performances.[5] Aomine was similarly protective over Ryōta Kise following his match against Fukuda Sōgō Academy, as he chose to wait outside the venue to prevent Shōgo Haizaki from causing any further trouble for Kise or his team.[6]\",\n",
       "   'score': 0.9997063,\n",
       "   'raw_content': None},\n",
       "  {'title': \"Kuroko's Basketball: Every Main Character's Age, Height & Birthday\",\n",
       "   'url': 'https://gamerant.com/kurokos-basketball-every-main-characters-age-height-birthday/',\n",
       "   'content': \"8 Daiki Aomine Aomine is the former ace of the Generation of Miracles. He plays as a power forward for Tōō academy's basketball team. Aomine is one of the\",\n",
       "   'score': 0.99923277,\n",
       "   'raw_content': None},\n",
       "  {'title': \"10 Best Kuroko's Basketball Players, Ranked - Screen Rant\",\n",
       "   'url': 'https://screenrant.com/kurokos-basketball-best-players-ranked/',\n",
       "   'content': '3 Aomine Daiki - The Monster Power Forward The super scorer and ace of the Generation of Miracles, 192 cm (6\\' 3½\") Power Forward Aomine Daiki is the fastest athlete in the series and can score from any position on the court with his formless shot, while at high speeds and even behind the rim. Daiki is free-spirited and has an unorthodox street',\n",
       "   'score': 0.99903405,\n",
       "   'raw_content': None},\n",
       "  {'title': \"Kuroko's Basketball: 10 Strongest Players, Ranked - Screen Rant\",\n",
       "   'url': 'https://screenrant.com/kurokos-basketball-strongest-best-skilled-players-ranked/',\n",
       "   'content': 'The former ace of the Generation of Miracles and Kuroko\\'s \"light,\" Daiki Aomine is endowed with the greatest combination of skill and athleticism among all the players in Kuroko\\'s Basketball. Despite never practicing or receiving formal basketball training, Aomine is considered a monster on the court due to his speed, power, ball-handling',\n",
       "   'score': 0.9986904,\n",
       "   'raw_content': None},\n",
       "  {'title': 'Kuroko No Basket: 10 Characters That Are Like Real-Life NBA Players',\n",
       "   'url': 'https://gamerant.com/kuroko-no-basket-characters-similar-real-life-nba-players/',\n",
       "   'content': 'Aomine Daiki is the definition of winning mentality and individuality. He snd Michael are both shooting guards with unstoppable, unorthodox offensive moves, and killer instincts.',\n",
       "   'score': 0.99850464,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 3.76}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_client.search(\"Who is Aomine Daiki?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Кто такой Борис Рыжий?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'title': 'История легендарного поэта Бориса Рыжего, который прожил всего 26 лет ...',\n",
       "   'url': 'https://ngs.ru/text/culture/2024/09/09/74062475/',\n",
       "   'content': 'История поэта Бориса Рыжего, который ушел из жизни в 26 лет и прославился на весь мир История поэта Бориса Рыжего, который ушел из жизни в 26 лет и прославился на весь мир По его словам, Борис Рыжий «был и жил целиком в поэзии, а это\\xa0— смертельно». В 1991 году Рыжий пошел по стопам отца и поступил в Свердловский горный институт (на самом деле\\xa0— потому что больше было некуда). Писатель Евгений Касимов рассказал E1.RU, что был не так близко знаком с Борисом: несколько раз они работали вместе, делали передачи на радио и ходили друг к другу в гости. Хамство, невежество и мракобесие: врач-педиатр — о том, что его бесит в пациентах Хамство, невежество и мракобесие: врач-педиатр — о том, что его бесит в пациентах',\n",
       "   'score': 0.9940428,\n",
       "   'raw_content': None},\n",
       "  {'title': 'Рыжий, Борис Борисович — Википедия',\n",
       "   'url': 'https://ru.wikipedia.org/wiki/Рыжий,_Борис_Борисович',\n",
       "   'content': 'В основе постановки\\xa0— поэзия Бориса Рыжего и музыка Сергея Никитина. 2012\\xa0год\\xa0— «Рыжий», театральный перформанс на стихи Бориса Рыжего уральского режиссёра Александра Вахова, показанный в Екатеринбурге в рамках 2-й Индустриальной биеннале современного искусства[13]. Фильм снимался в Екатеринбурге, в районе Вторчермета, где жил Борис Рыжий; режиссёр встречалась с его семьёй, друзьями, соседями, наблюдала за людьми на улицах, во дворах, магазинах\\xa0— за теми людьми, о которых писал поэт. С 5 по 8 сентября 2024\\xa0года в Екатеринбурге организованы «Дни Бориса Рыжего»\\xa0— серия мероприятий, посвящённых 50-летию со дня рождения поэта[36]. ↑ \"Борис Рыжий — Я работал на драге в посёлке Кытлым: читать стих, текст стихотворения поэта классика на РуСтих\". История поэта Бориса Рыжего, который ушёл из жизни в 26 лет и прославился на весь мир\\xa0\\xa0(рус.).',\n",
       "   'score': 0.99253935,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 4.09}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_client.search(\"Кто такой Борис Рыжий?\", max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = \"\"\"\n",
    "    SYSTEM:\n",
    "    You are an expert at routing a user question to a vectorstore or web search. \n",
    "    Vectorstore is consists of the quotes of Marcus Aurelius. If there is an emotion or need for\n",
    "    an advicce for life situation or just a complain or an advice, \n",
    "    use the vectorstore. For all other questions use web-search\n",
    "    Give a binary choice 'web_search' or 'vectorstore' based on the question. Return a string with a single word 'web_search' or 'vectorstore' and \n",
    "    no premable or explaination. \n",
    "\n",
    "    Example:\n",
    "        Question: I want to learn good morals and the government of my temper.\n",
    "        Answer: 'vectorstore'\n",
    "\n",
    "    USER:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoic_prompt = \"\"\"\n",
    "    SYSTEM:\n",
    "    You are a multilingual string merger. You have a user complain about something emotional in any language.\n",
    "    You have a tool with a list of closest quotes \n",
    "    from Marcus Aurelius. Yus should pick up a most appropriate one quote and return it with the prefix \n",
    "    \"That is what Marcus Avrelius said on this topic:\" You must not rephrase the \n",
    "    quote or use any thoughts of yours. Just prefix and quote no metter what. Answer only in English.\n",
    "\n",
    "    Example:\n",
    "        Question: I want to learn good morals and the government of my temper.\n",
    "        Quotes:[\"Be not disgusted, nor discouraged, nor dissatisfied,\n",
    "          if thou dost not succeed in doing everything according to right principles.\\n\",\n",
    "  \"Examine men's ruling principles, even those of the wise, what kind of things they avoid, and what kind they pursue.\\n\"]\n",
    "\n",
    "        Answer: \"That is what Marcus Avrelius said on this topic: Be not disgusted, nor discouraged, nor dissatisfied,\n",
    "          if thou dost not succeed in doing everything according to right principles\n",
    "\n",
    "    USER:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_prompt = \"\"\"\n",
    "    SYSTEM:\n",
    "    You are a multilingual search system. you have a qustion from user and a serach results. You need to the closest answer. \n",
    "    Answer always in English.\n",
    "\n",
    "    USER:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vectorstore'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_question = \"What can I do with my shitty life???\"\n",
    "\n",
    "llm_pipeline(f\"{router_prompt} {curr_question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'web_search'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_question = \"Who is Uzumaki Naruto?\"\n",
    "\n",
    "llm_pipeline(f\"{router_prompt} {curr_question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent python class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results(query: str, max_results=2):\n",
    "    return tavily_client.search(query, max_results=max_results)[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_step_completion(user_query):\n",
    "    return llm_pipeline(f\"{router_prompt} {user_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_step(first_step_completion, curr_question):\n",
    "    if first_step_completion == \"web_search\":\n",
    "        search_results = get_search_results(curr_question, max_results=2)\n",
    "        return llm_pipeline( f\"{search_prompt} {curr_question}, SEARCH_RESULTS: {search_results}\" )\n",
    "\n",
    "    elif first_step_completion == \"vectorstore\":\n",
    "        store_search = collection.query(query_texts=[curr_question], n_results=2)[\n",
    "            \"documents\"\n",
    "        ]\n",
    "        return llm_pipeline( f\"{stoic_prompt} {curr_question}, QUOTES: {store_search}\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(user_query):\n",
    "    first_step_res = first_step_completion(user_query)\n",
    "    return second_step(first_step_res, user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "                        model=\"gpt-4o\", \n",
    "                        temperature=0,\n",
    "                        messages=self.messages)\n",
    "        return completion.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError('422 Client Error: unknown for url: https://api.smith.langchain.com/runs/batch', '{\"detail\":\"int too big to convert\"}')\n",
      "Failed to batch ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError('422 Client Error: unknown for url: https://api.smith.langchain.com/runs/batch', '{\"detail\":\"int too big to convert\"}')\n",
      "Failed to batch ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError('422 Client Error: unknown for url: https://api.smith.langchain.com/runs/batch', '{\"detail\":\"int too big to convert\"}')\n",
      "Failed to batch ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError('422 Client Error: unknown for url: https://api.smith.langchain.com/runs/batch', '{\"detail\":\"int too big to convert\"}')\n",
      "Failed to batch ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError('422 Client Error: unknown for url: https://api.smith.langchain.com/runs/batch', '{\"detail\":\"int too big to convert\"}')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'That is what Marcus Aurelius said on this topic: From my grandfather Verus I learned good morals and the government of my temper.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"I want to learn good morals and the government of my temper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That is what Marcus Aurelius said on this topic: Do not have such an opinion of things as he has who does thee wrong, or such as he wishes thee to have, but look at them as they are in truth.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"Some truths are not for you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That is what Marcus Aurelius said on this topic: Hast thou seen those things? Look also at these. Do not disturb thyself. Make thyself all simplicity.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"Shitty life! How to change it???\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the search results, the closest answer to the question \"Who is Uzumaki Naruto?\" is:\\n\\nNaruto Uzumaki is the titular protagonist of the manga Naruto, created by Masashi Kishimoto. He is a ninja from the fictional Hidden Leaf Village.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"Who is Uzumaki Naruto?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the search results, Daiki Aomine is a character from the anime series \"Kuroko no Basuke\" (also known as \"Kuroko\\'s Basketball\"). He is the ace player of the Generation of Miracles and was the former partner of Tetsuya Kuroko in Teikō Junior High. Aomine is known for his aggressive and unpredictable playing style, which is made even more powerful by Kuroko\\'s misdirection. He is incredibly fast and versatile, with an uncanny ability to shoot from anywhere on the court.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"Who is Aomine Daiki?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tavily_search(query:str, max_results=2) -> dict:\n",
    "    \"\"\"\n",
    "    Searches actual information in the Tavily system.\n",
    "\n",
    "    Result example:\n",
    "    'query': 'Who is Aomine Daiki?',\n",
    "     max_results=2\n",
    "\n",
    "  {\n",
    "    'query': 'Who is Aomine Daiki?',\n",
    "    'follow_up_questions': None,\n",
    "    'answer': None,\n",
    "    'images': [],\n",
    "    'results': [\n",
    "    {'title': \"Aomine Daiki: The Phenomenal Basketball Star of Kuroko's Basketball\",\n",
    "    'url': 'https://dailyflares.com/aomine-daiki/',\n",
    "    'content': \"Aomine Daiki is a standout character in the popular anime and manga series Kuroko's Basketball. Known for his exceptional basketball skills and charismatic personality, Aomine has captured the hearts of fans worldwide. This article delves into the life and career of Aomine Daiki, exploring his role in Kuroko's Basketball, his basketball\",\n",
    "    'score': 0.9998233,\n",
    "    'raw_content': None},\n",
    "    {'title': 'Daiki Aomine - Kuroko no Basuke Wiki',\n",
    "    'url': 'https://kurokonobasuke.fandom.com/wiki/Daiki_Aomine',\n",
    "    'content': \"Daiki Aomine (青峰 大輝 Aomine Daiki) was the ace player of the renowned Generation of Miracles and was the former partner/light of Tetsuya Kuroko in Teikō Junior High. After hearing a benched teammate insult Tetsuya Kuroko and his style of play during a match against Seirin High, Aomine did not hesitate to slam him against the lockers and warn that he, as someone who couldn't even earn a spot on the court, had no right to comment on the players' performances.[5] Aomine was similarly protective over Ryōta Kise following his match against Fukuda Sōgō Academy, as he chose to wait outside the venue to prevent Shōgo Haizaki from causing any further trouble for Kise or his team.[6]\",\n",
    "    'score': 0.9997063,\n",
    "    'raw_content': None}\n",
    "    ]\n",
    "   }\n",
    "    \"\"\"\n",
    "    return tavily_client.search(query, max_results=max_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stoic_collection_search(query, n_results) -> dict:\n",
    "    \"\"\"\n",
    "    Searches a stoic quote in a collection. Use when needed advice on an emotional or life-relational situation.\n",
    "\n",
    "    {\n",
    "    'ids': [['id1', 'id15']],\n",
    "    'distances': [[0.6908390522003174, 1.1410863399505615]],\n",
    "    'metadatas': [[None, None]],\n",
    "    'embeddings': None,\n",
    "    'documents': [['From my grandfather Verus I learned good morals and the government of my temper.\\n',\n",
    "    'From Maximus I learned self-government, and not to be led aside by anything; and cheerfulness in all circumstances, as well as in illness; and a just admixture in the moral character of sweetness and dignity, and to do what was set before me without complaining. I observed that everybody believed that he thought as he spoke, and that in all that he did he never had any bad intention; and he never showed amazement and surprise, and was never in a hurry, and never put off doing a thing, nor was perplexed nor dejected, nor did he ever laugh to disguise his vexation, nor, on the other hand, was he ever passionate or suspicious. He was accustomed to do acts of beneficence, and was ready to forgive, and was free from all falsehood; and he presented the appearance of a man who could not be diverted from right rather than of a man who had been improved. I observed, too, that no man could ever think that he was despised by Maximus, or ever venture to think himself a better man. He had also the art of being humorous in an agreeable way.\\n']],\n",
    "    'uris': None,\n",
    "    'data': None,\n",
    "    'included': ['metadatas', 'documents', 'distances']\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    return collection.query(\n",
    "        query_texts=[\n",
    "            query\n",
    "        ],\n",
    "        n_results=n_results,\n",
    "    ) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [stoic_collection_search, tavily_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg = \"\"\"\n",
    "    SYSTEM:\n",
    "    You are an expert at routing a user question to a vectorstore or web search. \n",
    "    Vectorstore is consists of the quotes of Marcus Aurelius. If there is an emotion or need for\n",
    "    an advicce for life situation or just a complain or an advice, \n",
    "    use the vectorstore. For all other questions use web-search\n",
    "    You should use stoic_collection_search or tavily_search based on the question. \n",
    "\n",
    "    USER:\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_pipeline([sys_msg] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretriever\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_retriever_tool\n\u001b[1;32m      3\u001b[0m retriever_tool \u001b[38;5;241m=\u001b[39m create_retriever_tool(\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mretriever\u001b[49m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieve_blog_posts\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m tools \u001b[38;5;241m=\u001b[39m [retriever_tool]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_blog_posts\",\n",
    "    \"Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_one(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"graph_state\": state['graph_state']}\n",
    "\n",
    "def route_node(user_query) -> Literal[\"web_search_node\", \"vectorestore_node\"]:\n",
    "    return llm_pipeline(f\"{router_prompt} {user_query}\") # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search_node(curr_question):\n",
    "    search_results = get_search_results(curr_question, max_results=2)\n",
    "    return llm_pipeline( f\"{search_prompt} {curr_question}, SEARCH_RESULTS: {search_results}\" )\n",
    "\n",
    "def stoic_search_node(curr_question):\n",
    "    store_search = collection.query(query_texts=[curr_question], n_results=2)[\n",
    "        \"documents\"\n",
    "    ]\n",
    "    return llm_pipeline( f\"{stoic_prompt} {curr_question}, QUOTES: {store_search}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    graph_state: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Build graph\n",
    "builder.add_node(\"router_node\", node_one)\n",
    "builder.add_node(\"web_search_node\", web_search_node)\n",
    "builder.add_node(\"vectorestore_node\", stoic_search_node)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"router_node\")\n",
    "builder.add_conditional_edges(\"router_node\", route_node)\n",
    "builder.add_edge(\"web_search_node\", END)\n",
    "builder.add_edge(\"vectorestore_node\", END)\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"graph_state\" : \"Hi, this is Lance.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
